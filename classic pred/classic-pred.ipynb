{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 11967588,
     "sourceType": "datasetVersion",
     "datasetId": 7525362
    }
   ],
   "dockerImageVersionId": 31041,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    f1_score, accuracy_score, recall_score, precision_score, \n",
    "    precision_recall_curve, confusion_matrix, roc_auc_score, \n",
    "    matthews_corrcoef, roc_curve\n",
    ")\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.608610Z",
     "iopub.execute_input": "2025-05-28T14:49:22.609328Z",
     "iopub.status.idle": "2025-05-28T14:49:22.613937Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.609302Z",
     "shell.execute_reply": "2025-05-28T14:49:22.613074Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### ðŸ“Š Metric Calculation Utilities\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def get_aupr(pre, rec):\n",
    "    pr_value = 0.0\n",
    "    for ii in range(len(rec[:-1])):\n",
    "        x_r, x_l = rec[ii], rec[ii+1]\n",
    "        y_t, y_b = pre[ii], pre[ii+1]\n",
    "        tempo = abs(x_r - x_l) * (y_t + y_b) * 0.5\n",
    "        pr_value += tempo\n",
    "    return pr_value\n",
    "\n",
    "def scores(y_test, y_pred, th=0.5):           \n",
    "    y_predlabel = [(0. if item < th else 1.) for item in y_pred]\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predlabel).flatten()\n",
    "    SPE = tn / (tn + fp)\n",
    "    MCC = matthews_corrcoef(y_test, y_predlabel)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    sen, spe, pre, f1, mcc, acc, auc, tn, fp, fn, tp = np.array([\n",
    "        recall_score(y_test, y_predlabel), SPE, precision_score(y_test, y_predlabel), \n",
    "        f1_score(y_test, y_predlabel), MCC, accuracy_score(y_test, y_predlabel), \n",
    "        roc_auc_score(y_test, y_pred), tn, fp, fn, tp\n",
    "    ])\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    aupr = get_aupr(precision, recall)\n",
    "    return [aupr, auc, f1, acc, sen, spe, pre, fpr, tpr, precision, recall]\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.615080Z",
     "iopub.execute_input": "2025-05-28T14:49:22.615396Z",
     "iopub.status.idle": "2025-05-28T14:49:22.630045Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.615373Z",
     "shell.execute_reply": "2025-05-28T14:49:22.629173Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# --- Utility Functions ---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def combine_features(phage_dna, host_dna, phage_pro, host_pro):\n    combined = np.concatenate([phage_dna, host_dna, phage_pro, host_pro], axis=1)\n    return combined",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.631359Z",
     "iopub.execute_input": "2025-05-28T14:49:22.631599Z",
     "iopub.status.idle": "2025-05-28T14:49:22.648218Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.631573Z",
     "shell.execute_reply": "2025-05-28T14:49:22.647447Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def load_feature_vector(file_path):\n    return np.loadtxt(file_path)",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.648995Z",
     "iopub.execute_input": "2025-05-28T14:49:22.649286Z",
     "iopub.status.idle": "2025-05-28T14:49:22.662720Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.649258Z",
     "shell.execute_reply": "2025-05-28T14:49:22.661931Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def obtain_features(phage_list, host_list, labels, dna_base, pro_base):\n",
    "    X_phage_dna, X_host_dna = [], []\n",
    "    X_phage_pro, X_host_pro = [], []\n",
    "    for p, h in zip(phage_list, host_list):\n",
    "        X_phage_dna.append(load_feature_vector(os.path.join(dna_base, 'phage', f'{p}.txt')))\n",
    "        X_host_dna.append(load_feature_vector(os.path.join(dna_base, 'bacteria', f'{h}.txt')))\n",
    "        X_phage_pro.append(load_feature_vector(os.path.join(pro_base, 'phage', f'{p}.txt')))\n",
    "        X_host_pro.append(load_feature_vector(os.path.join(pro_base, 'bacteria', f'{h}.txt')))\n",
    "    return (np.array(X_phage_dna), np.array(X_host_dna),\n",
    "            np.array(X_phage_pro), np.array(X_host_pro),\n",
    "            np.array(labels))"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.664342Z",
     "iopub.execute_input": "2025-05-28T14:49:22.664929Z",
     "iopub.status.idle": "2025-05-28T14:49:22.677837Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.664899Z",
     "shell.execute_reply": "2025-05-28T14:49:22.677181Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# --- Load interaction matrix ---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "interaction_matrix_path = \"escherichia_dataset_features/ordinal_interaction_matrix.csv\"\n",
    "csv_output_path = \"escherichia_dataset_features/interaction_matrix.csv\"\n",
    "\n",
    "dna_base = './escherichia_dataset_features/dna_features_ordinal_data'\n",
    "pro_base = './escherichia_dataset_features/prot_features_ordinal_data'"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "interaction_matrix_path = \"klebsiella_dataset_features/phage_host_interactions.csv\"\n",
    "\n",
    "dna_base = './klebsiella_dataset_features/dna_features'\n",
    "pro_base = './klebsiella_dataset_features/protein_features'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.678639Z",
     "iopub.execute_input": "2025-05-28T14:49:22.678907Z",
     "iopub.status.idle": "2025-05-28T14:49:22.713304Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.678871Z",
     "shell.execute_reply": "2025-05-28T14:49:22.712484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get list of phages and hosts based on files present\n",
    "if interaction_matrix_path.endswith('.xlsx'):\n",
    "    #Transposed because this dataset has another the wrong shape\n",
    "    df = pd.read_excel(interaction_matrix_path, index_col=0).T\n",
    "    df.to_csv(csv_output_path)\n",
    "    interaction_matrix_path = csv_output_path # Update path to CSV\n",
    "else:\n",
    "    df = pd.read_csv(interaction_matrix_path, index_col=0, sep=';')\n",
    "\n",
    "valid_phages = set([f.split('.')[0] for f in os.listdir(dna_base+\"/phage\") if f.endswith('.txt')])\n",
    "valid_hosts = set([f.split('.')[0] for f in os.listdir(pro_base+\"/bacteria\") if f.endswith('.txt')])\n",
    "#filter unused interaction since matrix to large\n",
    "df = df.loc[df.index.intersection(valid_hosts), df.columns.intersection(valid_phages)]\n",
    "phages = df.columns.tolist()\n",
    "hosts = df.index.tolist()\n",
    "print(len(phages))\n",
    "print(len(hosts))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Prepare data as list of (phage, host, label)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "all_data = []\n",
    "\n",
    "for p in phages:\n",
    "    for h in hosts:\n",
    "        label = df.loc[h, p]\n",
    "        if pd.isna(label):\n",
    "            continue  # Skip missing values\n",
    "        binary_label = 1 if label >= 1 else 0\n",
    "        all_data.append([p, h, binary_label])"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.713967Z",
     "iopub.execute_input": "2025-05-28T14:49:22.714197Z",
     "iopub.status.idle": "2025-05-28T14:49:22.867975Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.714181Z",
     "shell.execute_reply": "2025-05-28T14:49:22.867232Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dummy Classifier as Baseline"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Prepare full dataset for baseline\n",
    "phage_list = [x[0] for x in all_data]\n",
    "host_list = [x[1] for x in all_data]\n",
    "labels = [x[2] for x in all_data]\n",
    "\n",
    "# Extract features for the full dataset\n",
    "X_phage_dna, X_host_dna, X_phage_pro, X_host_pro, y_all = obtain_features(\n",
    "    phage_list, host_list, labels, dna_base, pro_base\n",
    ")\n",
    "X_all = combine_features(X_phage_dna, X_host_dna, X_phage_pro, X_host_pro)\n",
    "\n",
    "# Train and evaluate DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_all, y_all)\n",
    "y_dummy_prob = dummy.predict_proba(X_all)[:, 1]\n",
    "\n",
    "# Evaluate with custom metrics\n",
    "dummy_metrics = scores(y_all, y_dummy_prob)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Dummy Classifier Metrics:\")\n",
    "print(f\"AUPR: {dummy_metrics[0]:.4f}\")\n",
    "print(f\"AUC:  {dummy_metrics[1]:.4f}\")\n",
    "print(f\"F1:   {dummy_metrics[2]:.4f}\")\n",
    "print(f\"ACC:  {dummy_metrics[3]:.4f}\")\n",
    "print(f\"SEN:  {dummy_metrics[4]:.4f}\")\n",
    "print(f\"SPE:  {dummy_metrics[5]:.4f}\")\n",
    "print(f\"PREC: {dummy_metrics[6]:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Unpack for plotting\n",
    "fpr, tpr = dummy_metrics[7], dummy_metrics[8]\n",
    "precision_curve, recall_curve = dummy_metrics[9], dummy_metrics[10]\n",
    "\n",
    "# --- ROC Curve ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"Dummy (AUC = {dummy_metrics[1]:.2f})\", color='gray')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (DummyClassifier)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Precision-Recall Curve ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall_curve, precision_curve, label=f\"Dummy (AUPR = {dummy_metrics[0]:.2f})\", color='gray')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (DummyClassifier)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_dummy_label = [1 if p >= 0.5 else 0 for p in y_dummy_prob]\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_all, y_dummy_label, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (DummyClassifier)\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### ðŸ§ª Model Training and Evaluation (with Metrics)",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare full feature set for grid search (using all data)\n",
    "all_phages = [x[0] for x in all_data]\n",
    "all_hosts = [x[1] for x in all_data]\n",
    "all_labels = [x[2] for x in all_data]\n",
    "\n",
    "X_phage_dna, X_host_dna, X_phage_pro, X_host_pro, y_all = obtain_features(\n",
    "    all_phages, all_hosts, all_labels, dna_base, pro_base)\n",
    "X_all_combined = combine_features(X_phage_dna, X_host_dna, X_phage_pro, X_host_pro)\n",
    "\n",
    "print(\"Shape of X_all_combined:\", X_all_combined.shape)\n",
    "print(\"Shape of y_all:\", len(y_all))\n",
    "\n",
    "#imbalance left out -> achieved worse results for an increase in f1 of 0.001\n",
    "imbalance = sum([1 for i in y_all if i == 1]) / sum([1 for i in y_all if i == 0])\n",
    "\n",
    "# Set up model and parameter grid\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200],\n",
    "    'max_depth': [5, 7, None],\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'scale_pos_weight': [1]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_all_combined, y_all)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "#Best hyperparameters: {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 200, 'scale_pos_weight': 1}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "results_all = []\n",
    "fprs, tprs, precisions, recalls = [], [], [], []\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "labels = [row[2] for row in all_data]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_data, labels)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "\n",
    "    train_set = [all_data[i] for i in train_idx]\n",
    "    val_set = [all_data[i] for i in val_idx]\n",
    "\n",
    "    train_phages = [x[0] for x in train_set]\n",
    "    train_hosts = [x[1] for x in train_set]\n",
    "    train_labels = [x[2] for x in train_set]\n",
    "\n",
    "    val_phages = [x[0] for x in val_set]\n",
    "    val_hosts = [x[1] for x in val_set]\n",
    "    val_labels = [x[2] for x in val_set]\n",
    "\n",
    "    X_phage_dna_tr, X_host_dna_tr, X_phage_pro_tr, X_host_pro_tr, y_train = obtain_features(\n",
    "        train_phages, train_hosts, train_labels, dna_base, pro_base)\n",
    "    X_phage_dna_val, X_host_dna_val, X_phage_pro_val, X_host_pro_val, y_val = obtain_features(\n",
    "        val_phages, val_hosts, val_labels, dna_base, pro_base)\n",
    "\n",
    "    X_train_combined = combine_features(X_phage_dna_tr, X_host_dna_tr, X_phage_pro_tr, X_host_pro_tr)\n",
    "    X_val_combined = combine_features(X_phage_dna_val, X_host_dna_val, X_phage_pro_val, X_host_pro_val)\n",
    "\n",
    "    # Use the best parameters\n",
    "    best_model = XGBClassifier(eval_metric='logloss', **best_params)\n",
    "    best_model.fit(X_train_combined, y_train)\n",
    "    y_pred_prob = best_model.predict_proba(X_val_combined)[:, 1]\n",
    "\n",
    "    fold_metrics = scores(y_val, y_pred_prob)\n",
    "\n",
    "    results_all.append(fold_metrics[:7])\n",
    "    fprs.append(fold_metrics[7])\n",
    "    tprs.append(fold_metrics[8])\n",
    "    precisions.append(fold_metrics[9])\n",
    "    recalls.append(fold_metrics[10])\n",
    "\n",
    "    print(f\"Fold {fold+1} | AUPR: {fold_metrics[0]:.4f}, AUC: {fold_metrics[1]:.4f}, F1: {fold_metrics[2]:.4f}, Acc: {fold_metrics[3]:.4f}\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-05-28T14:49:22.869511Z",
     "iopub.execute_input": "2025-05-28T14:49:22.869736Z",
     "iopub.status.idle": "2025-05-28T14:52:55.457847Z",
     "shell.execute_reply.started": "2025-05-28T14:49:22.869721Z",
     "shell.execute_reply": "2025-05-28T14:52:55.457104Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“‰ Plotting Metrics Across Folds"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot ROC Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(fprs)):\n",
    "    plt.plot(fprs[i], tprs[i], label=f'Fold {i+1}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"XGBoost ROC Curve Across Folds\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot PR Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(precisions)):\n",
    "    plt.plot(recalls[i], precisions[i], label=f'Fold {i+1}')\n",
    "plt.title(\"XGBoost Precision-Recall Curve Across Folds\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“¦ Summary Boxplot of All Metrics"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metric_names = [\"AUPR\", \"ROC-AUC\", \"F1\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"Precision\"]\n",
    "results_array = np.array(results_all)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot(results_array, labels=metric_names, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='black'),\n",
    "            medianprops=dict(color='red'),\n",
    "            whiskerprops=dict(color='black'))\n",
    "plt.title(\"Cross-Fold Metric Distribution\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“‹ Fold-wise Metric Table\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results_df = pd.DataFrame(results_all, columns=metric_names)\n",
    "results_df.index = [f\"Fold {i+1}\" for i in range(len(results_all))]\n",
    "display(results_df)\n",
    "\n",
    "print(\"Mean Metrics:\")\n",
    "print(results_df.mean())  # This should always output something if the DataFrame is valid\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸŒ² Random Forest Model with Grid SearchCV\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare full feature set\n",
    "all_phages = [x[0] for x in all_data]\n",
    "all_hosts = [x[1] for x in all_data]\n",
    "all_labels = [x[2] for x in all_data]\n",
    "\n",
    "X_phage_dna, X_host_dna, X_phage_pro, X_host_pro, y_all = obtain_features(\n",
    "    all_phages, all_hosts, all_labels, dna_base, pro_base)\n",
    "X_all_combined = combine_features(X_phage_dna, X_host_dna, X_phage_pro, X_host_pro)\n",
    "\n",
    "# Class weights for imbalance\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=y_all)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# Hyperparameter grid\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# Grid Search on full data\n",
    "rf_base = RandomForestClassifier(class_weight=class_weight_dict, random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(estimator=rf_base, param_grid=rf_param_grid,\n",
    "                           scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_all_combined, y_all)\n",
    "best_rf_params = grid_search.best_params_\n",
    "print(\"Best RF hyperparameters:\", best_rf_params)\n",
    "#{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_results_all = []\n",
    "rf_fprs, rf_tprs, rf_precisions, rf_recalls = [], [], [], []\n",
    "kf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "labels = [row[2] for row in all_data]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_data, labels)):\n",
    "    print(f\"RF Fold {fold+1}\")\n",
    "\n",
    "    train_set = [all_data[i] for i in train_idx]\n",
    "    val_set = [all_data[i] for i in val_idx]\n",
    "\n",
    "    train_phages = [x[0] for x in train_set]\n",
    "    train_hosts = [x[1] for x in train_set]\n",
    "    train_labels = [x[2] for x in train_set]\n",
    "\n",
    "    val_phages = [x[0] for x in val_set]\n",
    "    val_hosts = [x[1] for x in val_set]\n",
    "    val_labels = [x[2] for x in val_set]\n",
    "\n",
    "    X_phage_dna_tr, X_host_dna_tr, X_phage_pro_tr, X_host_pro_tr, y_train = obtain_features(\n",
    "        train_phages, train_hosts, train_labels, dna_base, pro_base)\n",
    "    X_phage_dna_val, X_host_dna_val, X_phage_pro_val, X_host_pro_val, y_val = obtain_features(\n",
    "        val_phages, val_hosts, val_labels, dna_base, pro_base)\n",
    "\n",
    "    X_train_combined = combine_features(X_phage_dna_tr, X_host_dna_tr, X_phage_pro_tr, X_host_pro_tr)\n",
    "    X_val_combined = combine_features(X_phage_dna_val, X_host_dna_val, X_phage_pro_val, X_host_pro_val)\n",
    "\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=y_train)\n",
    "    class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "    # Train best model with fixed params\n",
    "    best_rf = RandomForestClassifier(class_weight=class_weight_dict, random_state=42, n_jobs=-1, **best_rf_params)\n",
    "    best_rf.fit(X_train_combined, y_train)\n",
    "    y_pred_prob = best_rf.predict_proba(X_val_combined)[:, 1]\n",
    "\n",
    "    rf_fold_metrics = scores(y_val, y_pred_prob)\n",
    "    rf_results_all.append(rf_fold_metrics[:7])\n",
    "    rf_fprs.append(rf_fold_metrics[7])\n",
    "    rf_tprs.append(rf_fold_metrics[8])\n",
    "    rf_precisions.append(rf_fold_metrics[9])\n",
    "    rf_recalls.append(rf_fold_metrics[10])\n",
    "\n",
    "    print(f\"Fold {fold+1} | AUPR: {rf_fold_metrics[0]:.4f}, AUC: {rf_fold_metrics[1]:.4f}, \"\n",
    "          f\"F1: {rf_fold_metrics[2]:.4f}, Acc: {rf_fold_metrics[3]:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸŒ² Random Forest ROC & PR Curves"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(rf_fprs)):\n",
    "    plt.plot(rf_fprs[i], rf_tprs[i], label=f'Fold {i+1}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"Random Forest ROC Curve Across Folds\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(rf_precisions)):\n",
    "    plt.plot(rf_recalls[i], rf_precisions[i], label=f'Fold {i+1}')\n",
    "plt.title(\"Random Forest Precision-Recall Curve Across Folds\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“¦ Metric Boxplot: XGBoost vs Random Forest"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_metric_names = [\"AUPR\", \"ROC-AUC\", \"F1\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"Precision\"]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.boxplot([np.array(results_all)[:,i] for i in range(7)], \n",
    "            positions=np.arange(1, 8) - 0.2, widths=0.3, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue'), medianprops=dict(color='blue'), labels=all_metric_names)\n",
    "\n",
    "plt.boxplot([np.array(rf_results_all)[:,i] for i in range(7)], \n",
    "            positions=np.arange(1, 8) + 0.2, widths=0.3, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightgreen'), medianprops=dict(color='green'))\n",
    "\n",
    "plt.legend(['XGBoost - blue', 'Random Forest - green'])\n",
    "plt.title(\"Metric Distribution Comparison: XGBoost vs Random Forest\")\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(1, 8), all_metric_names)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“‹ Random Forest Fold-wise Metrics"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_df = pd.DataFrame(rf_results_all, columns=all_metric_names)\n",
    "rf_df.index = [f\"Fold {i+1}\" for i in range(len(rf_results_all))]\n",
    "display(rf_df)\n",
    "\n",
    "print(\"Random Forest - Mean Metrics:\")\n",
    "print(rf_df.mean())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“Š Side-by-side Mean Metrics (XGBoost vs RF)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_mean = pd.DataFrame([np.mean(results_all, axis=0)], columns=all_metric_names, index=[\"XGBoost\"])\n",
    "rf_mean = pd.DataFrame([np.mean(rf_results_all, axis=0)], columns=all_metric_names, index=[\"Random Forest\"])\n",
    "\n",
    "display(pd.concat([xgb_mean, rf_mean]))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
